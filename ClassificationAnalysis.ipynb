{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from statistics import mean, median\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import fasttext\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "Path('data').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# download datafile and unzip\n",
    "zipurl = 'ZIP-URL-HERE'\n",
    "zippassword = 'ZIP-PASSWORD-HERE'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data', None, zippassword.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/data_redacted.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Data Processing](#dataprocess)\n",
    "* [Data Analysis](#dataanalysis)\n",
    "    * [Magic in URL](#magicurl)\n",
    "    * [Text Content](#textcontent)\n",
    "* [Train Model with Fasttext](#trainfasttext)\n",
    "    * [Manually Trained Wordvec](#manualwordvec)\n",
    "    * [Pretrained Wordvec](#pretrainedwordvec)\n",
    "* [Evaluation](#evaluation)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing <a class=\"anchor\" id=\"dataprocess\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a quick look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have normal text in title and text field, let's do some simple processing for text, like remove numbers (they don't contain much information about article category), make them lowercase, remove punctation, and remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_STOPWORDS = set(stopwords.words('english'))\n",
    "def tokenize(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\b[^\\d\\W]+\\b')\n",
    "    token_list = tokenizer.tokenize(text)\n",
    "    \n",
    "    return ' '.join([w.lower() for w in token_list if len(w) > 1 and w not in ENGLISH_STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_title'] = df['title'].apply(tokenize)\n",
    "df['cleaned_text'] = df['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the url, we can do more than normal processing because they have some interesting information. \n",
    "- Some website can be specialized in a small subset of category\n",
    "- The website url usually follows a structured path. Some websites use date or article category in the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_url(url):\n",
    "    # for url, fasttest way is to split by /\n",
    "    tokens = url.split('/')\n",
    "    if len(tokens) > 3:\n",
    "        # ignore the http and double slash, the website address is the 3rd\n",
    "        website_url = tokens[2]\n",
    "        # the final should contain article title\n",
    "        article_title = tokens[-1]\n",
    "        # we should clean the extensions to get the title\n",
    "        article_title = re.sub('\\.[\\w]{3,4}$', '', article_title)\n",
    "        article_title = tokenize(article_title)\n",
    "\n",
    "        # now the important part, the parts in between. Usually they contain the article categories or date, let's try to ignore numbers\n",
    "        article_cats = tokenize(' '.join([c for c in tokens[3:-1] if not re.search('\\d', c)]))\n",
    "        return website_url, article_cats, article_title\n",
    "    else:\n",
    "        return None, '', tokenize(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['website_url'], \\\n",
    "df['article_cats'], \\\n",
    "df['article_title'] = zip(*df['url'].apply(tokenize_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is looking fine so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis <a class=\"anchor\" id=\"dataanalysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to check some basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8646 entries of data, belong to 12 categories, which is quite small size of data. There are some unbalanced in data, however the lowest category still has 367 entries, which is not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic in URL <a class=\"anchor\" id=\"magicurl\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do some normal checking, let's focus to the URL, which can contain valuable information that we may need. As I said before, many website use category in the URL to organize the structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a wordcloud for the article cats that we extracted from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_cats = ' '.join([s for cat in df['article_cats'].tolist() for s in cat.split() if len(cat)>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=400).generate(all_article_cats)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure( figsize=(20,10) )\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ignore the word \"new\" and \"article\" for now because they have no meaning, and graph again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article_cats = all_article_cats.split(' ')\n",
    "all_article_cats = ' '.join([s for s in all_article_cats if s not in set(['new', 'article', 'articles'])])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400).generate(all_article_cats)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure( figsize=(20,10) )\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite interesting that the top words in the URL have some common grounds with the categories that we want to map. I want to try a simple method: match the words in url (excluding the article title and website) with the category mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_category_article_cats(category, article_cats):\n",
    "    '''\n",
    "    This function try to check if the category match any words with the article cats in url\n",
    "    '''\n",
    "    category_set = set(category.lower().split('_'))\n",
    "    if 'cars' in category_set:\n",
    "        category_set.add('car')\n",
    "    if 'motors' in category_set:\n",
    "        category_set.add('motor')\n",
    "        category_set.add('motoring')\n",
    "    if 'sports' in category_set:\n",
    "        category_set.add('sport')\n",
    "        \n",
    "    article_cat_set = set(article_cats.split(' '))\n",
    "    if 'life' in article_cat_set and 'style' in article_cat_set:\n",
    "        article_cat_set.add('lifestyle')\n",
    "    return not category_set.isdisjoint(article_cat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_category_article_cats_false(category, article_cats):\n",
    "    '''\n",
    "    This function try to check if the article cats in url match other wrong categories\n",
    "    '''\n",
    "    all_category = set(['fashion', 'beauty', 'lifestyle', 'sports', 'technology', 'science', 'digital', 'life', 'money', 'business, news',\n",
    "                    'music', 'culture', 'travel', 'cars', 'motors', 'politics', 'people', 'shows'])\n",
    "    category_set = set(category.lower().split('_'))\n",
    "    other_category_set = all_category.difference(category_set)\n",
    "    if 'cars' in other_category_set:\n",
    "        other_category_set.add('car')\n",
    "    if 'motors' in other_category_set:\n",
    "        other_category_set.add('motor')\n",
    "        other_category_set.add('motoring')\n",
    "    if 'sports' in other_category_set:\n",
    "        other_category_set.add('sport')\n",
    "    \n",
    "    article_cat_set = set(article_cats.split(' '))\n",
    "    \n",
    "    if 'life' in article_cat_set and 'style' in article_cat_set:\n",
    "        article_cat_set.add('lifestyle')\n",
    "    return not other_category_set.isdisjoint(article_cat_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['check_article_cats'] = df.apply(lambda row: check_category_article_cats(row['category'], row['article_cats']), axis=1)\n",
    "df['check_article_cats_false'] = df.apply(lambda row: check_category_article_cats_false(row['category'], row['article_cats']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we test our theory to see if we can use matching between url and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['check_article_cats'] & ~df['check_article_cats_false']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can correctly categorize 2003, around 23% of data by just matching the url! How about False Positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = df[~df['check_article_cats'] & df['check_article_cats_false']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 248 articles, 2.86% that we wrongly map because the url matches one of the incorrect categories. Let's have a look at those articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some quick look in the data shows some interesting insights into the data\n",
    "- Some articles seem to be wrongly mapped, why stress article is in technology? Lionel Messi private life should be in sports or in people_shows when he is a sport star? Primary school admission process is  about technology?\n",
    "- Some categories are loosely defined. \"news\" category is too broad, because every article can be considered news. \"cars\" should be a subset of \"technology\". \"digital_life\" and \"technology\" can be mixed up in some ways.\n",
    "- If \"news\" is a general category (in case we couldn't fit the article in other categories), should we remove it from the category list and just assign it if the predict probability couldn't reach a specified threshold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the website that we grabbed articles from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['website_url'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the top websites are general news site, which can contain all kind of categories. Let's skip this information for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Content <a class=\"anchor\" id=\"textcontent\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the article titles and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['cleaned_title', 'cleaned_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_text = [len(x) for x in df['cleaned_text'].tolist()]\n",
    "print(mean(len_text))\n",
    "print(max(len_text))\n",
    "print(min(len_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some articles are more than 10 times the normal content, which can make the content too general for classification. We may need to find a way to capture the essential part of the article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model with Fasttext <a class=\"anchor\" id=\"trainfasttext\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose Fasttext model for text classification. Fasttext is a word embedding method that is similar to word2vec. Fasttext is designed to recognize rare words or not in the dictionary because it can learn prefixes and suffixes from training dataset. We can train the word vectors by training dataset, or download it from other sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my experience, I am quite satisfied with fasttext performance for text classification. We could explore other algorithms of course, but I believe fasttext is a solid choice in beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Trained Wordvec <a class=\"anchor\" id=\"manualwordvec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will train the wordvec by fasttext from our training dataset and use it for classifier. We need to do some processing steps for url, title and text, then combine them together in one. This step can be optimized later if we want to emphasize the importance of article cats that we get from url.\n",
    "\n",
    "Fasttext require a csv file without quoting, and the last word contains the label of the text, with __label__ prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(data, feature_fields):\n",
    "    # Remove spaces from topic names, so a topic is recognized as one word\n",
    "    # data.Topic = data.Topic.replace(' ','_', regex=True)\n",
    "    data[\"Text\"] = ''\n",
    "    for field in feature_fields:\n",
    "        data[\"Text\"] += data[field] + ' '\n",
    "    data[\"Label\"] = '__label__' + data[\"category\"]\n",
    "    data[\"TextWLabels\"] = data[\"Text\"] + ' ' + data[\"Label\"]\n",
    "    return data\n",
    "\n",
    "def train_model(train_data , wordNgrams, lr, epoch, feature_fields, dim=100, pretrained_vectors = None):\n",
    "    train_data = combine_text(train_data, feature_fields)\n",
    "    train_data = train_data[train_data['TextWLabels'].notnull()]\n",
    "    train_dataframe = train_data[['TextWLabels']]\n",
    "    \n",
    "   \n",
    "    train_dataframe.to_csv('training_file.csv', sep='\\t', encoding='utf-8', index=False, quoting=csv.QUOTE_NONE, escapechar='\"', header=False)\n",
    "     \n",
    "    if pretrained_vectors is None:\n",
    "        model = fasttext.train_supervised('training_file.csv', wordNgrams=wordNgrams, lr=lr, epoch=epoch, dim=dim)\n",
    "    else:\n",
    "        model = fasttext.train_supervised('training_file.csv', wordNgrams=wordNgrams, lr=lr, epoch=epoch, dim=dim, pretrainedVectors=pretrained_vectors)\n",
    "        \n",
    "    return model\n",
    "\n",
    "def predict(model, row, feature_fields):\n",
    "    clean_description = ''\n",
    "    for field in feature_fields:\n",
    "        clean_description += row[field] + ' '\n",
    "    clean_description = clean_description.replace('\\n', ' ')\n",
    "    clean_description = tokenize(clean_description)\n",
    "    clean_description = (clean_description + ' ') * 1\n",
    "    clean_description = clean_description.strip()\n",
    "    result = model.predict(clean_description,k=3)\n",
    "    \n",
    "    return result[0][0][9:], result[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should do a quick parameter tuning for 3 most important factors in fasttext: wordngrams, learning rate and epoch. I also design the training function to take different feature fields to see if we actually require all article features or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(temp_df):\n",
    "    data = []\n",
    "    threshold = 0\n",
    "    \n",
    "    for label in temp_df['category'].drop_duplicates().tolist():\n",
    "        true_positives = temp_df[(temp_df.predict_label == label) & (temp_df.category == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "        try:\n",
    "            precision = true_positives/temp_df[(temp_df.predict_label == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "        except:\n",
    "            precision = 0\n",
    "        try:\n",
    "            recall = true_positives/temp_df[temp_df.category == label].shape[0]\n",
    "        except:\n",
    "            recall = 0\n",
    "\n",
    "        try:\n",
    "            f1 = 2*precision*recall/(precision + recall)\n",
    "        except:\n",
    "            f1 = 0\n",
    "        number = temp_df[temp_df.category == label].shape[0]\n",
    "        data.append([label, precision, recall, f1, number])\n",
    "    stat_df = pd.DataFrame(data, columns = ['label', 'precision', 'recall', 'f1', 'count'])\n",
    "    macrof1 = stat_df['f1'].mean()\n",
    "    weightedf1 = stat_df['f1'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "    macroprecision = stat_df['precision'].mean()\n",
    "    weightedprecision = stat_df['precision'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "    macrorecall = stat_df['recall'].mean()\n",
    "    weightedrecall = stat_df['recall'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "    \n",
    "    print('Macro F1: {}'.format(macrof1))\n",
    "    print('Weighted F1: {}'.format(weightedf1))\n",
    "    print('Macro Precision: {}'.format(macroprecision))\n",
    "    print('Weighted Precision: {}'.format(weightedprecision))\n",
    "    print('Macro Recall: {}'.format(macrorecall))\n",
    "    print('Weighted Recall: {}'.format(weightedrecall))\n",
    "    \n",
    "    return stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(d, test_size = 0.2, stratify = d.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = df.copy()\n",
    "d[\"website_url\"] = d[\"website_url\"].fillna('')\n",
    "d[\"article_cats\"] = d[\"article_cats\"].fillna('')\n",
    "d[\"cleaned_title\"] = d[\"cleaned_title\"].fillna('')\n",
    "d[\"cleaned_text\"] = d[\"cleaned_text\"].fillna('')\n",
    "threshold = 0\n",
    "           \n",
    "for wordngrams in [1,2]:\n",
    "    for lr in [0.1, 0.25, 0.5]:\n",
    "        for epoch in [5, 10, 25]:\n",
    "            name = f'{wordngrams}|{lr}|{epoch}'\n",
    "            print(name)\n",
    "            \n",
    "            feature_fields = [\"website_url\", \"article_cats\", \"cleaned_title\", \"cleaned_text\"]\n",
    "            print(feature_fields)\n",
    "            model = train_model(train_df, wordngrams,lr,epoch, feature_fields)\n",
    "            test_df['predict_label'], test_df['predict_value'] = zip(*test_df.apply(lambda x: predict(model, x, feature_fields), axis=1))\n",
    "            evaluate_performance(test_df)\n",
    "            \n",
    "            print('---------')\n",
    "            \n",
    "            feature_fields = [\"article_cats\", \"cleaned_title\", \"cleaned_text\"]\n",
    "            print(feature_fields)\n",
    "            model = train_model(train_df, wordngrams,lr,epoch, feature_fields)\n",
    "            test_df['predict_label'], test_df['predict_value'] = zip(*test_df.apply(lambda x: predict(model, x, feature_fields), axis=1))\n",
    "            evaluate_performance(test_df)\n",
    "            \n",
    "            print('---------')\n",
    "            \n",
    "            feature_fields = [\"cleaned_title\", \"cleaned_text\"]\n",
    "            print(feature_fields)\n",
    "            model = train_model(train_df, wordngrams,lr,epoch, feature_fields)\n",
    "            test_df['predict_label'], test_df['predict_value'] = zip(*test_df.apply(lambda x: predict(model, x, feature_fields), axis=1))\n",
    "            evaluate_performance(test_df)\n",
    "            \n",
    "            print('===============================================')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting fact is that there is not much difference to overall performance when we exclude the url (website_url and article_cats) while training the fasttext model. It can happen because we just concatenate the text normally without emphasizing the importance of those features. There is not much difference when wordngrams is 1 or 2, but let's choose the best one for now: worngrams = 1, lr = 0.5, epoch = 25 with weighted F1 of 88.51%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Wordvec <a class=\"anchor\" id=\"pretrainedwordvec\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training dataset is quite small for our purpose: news classification. The number of articles could not cover the whole English dictionary and we may have problems with new words that are completely different. Fortunately there are pretrained wordvec that are trained from big news source. We can integrate it as wordembedding for our fasttext model and use it for classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, I will use the small ones, 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory\n",
    "Path(\"pretrained_wordvec\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# download the pretrained wordvec\n",
    "zipurl = 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('pretrained_wordvec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = df.copy()\n",
    "d[\"website_url\"] = d[\"website_url\"].fillna('')\n",
    "d[\"article_cats\"] = d[\"article_cats\"].fillna('')\n",
    "d[\"cleaned_title\"] = d[\"cleaned_title\"].fillna('')\n",
    "d[\"cleaned_text\"] = d[\"cleaned_text\"].fillna('')\n",
    "threshold = 0\n",
    "           \n",
    "for wordngrams in [1,2]:\n",
    "    for lr in [0.1, 0.25, 0.5]:\n",
    "        for epoch in [5, 10, 25]:\n",
    "            name = f'{wordngrams}|{lr}|{epoch}'\n",
    "            print(name)\n",
    "            \n",
    "            feature_fields = [\"website_url\", \"article_cats\", \"cleaned_title\", \"cleaned_text\"]\n",
    "            print(feature_fields)\n",
    "            model = train_model(train_df, wordngrams,lr,epoch, feature_fields, dim=300, pretrained_vectors = 'pretrained_wordvec/wiki-news-300d-1M.vec')\n",
    "            test_df['predict_label'], test_df['predict_value'] = zip(*test_df.apply(lambda x: predict(model, x, feature_fields), axis=1))\n",
    "            evaluate_performance(test_df)\n",
    "            \n",
    "            print('==========================')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could achieve up to 89.86% with wordngrams=1, lr=0.5, epoch=5, which is a noticable improvements! This confirmed that our dataset is still so small for the news and by utilizing the dictionary from other sources, we could achieve higher performance. I tried with 2 million word vectors trained on Common Crawl and got the weighted F1 score of 90.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation <a class=\"anchor\" id=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the improvements are not significant, and the time to train/load the big pretrained vectors are quite high, I would choose manually trained wordvectors based on training dataset for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For final evaluation of our classifier with the optimized parameters, we will do a repeated stratified K fold to ensure that the F1 score is unbiased to the train/split dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = df.copy()\n",
    "d[\"website_url\"] = d[\"website_url\"].fillna('')\n",
    "d[\"article_cats\"] = d[\"article_cats\"].fillna('')\n",
    "d[\"cleaned_title\"] = d[\"cleaned_title\"].fillna('')\n",
    "d[\"cleaned_text\"] = d[\"cleaned_text\"].fillna('')\n",
    "k = 5\n",
    "kfold = RepeatedStratifiedKFold(k, n_repeats=1, random_state=100)\n",
    "i=0\n",
    "result = []\n",
    "data = []\n",
    "threshold = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(d, d.category):\n",
    "    print(\"Running {}-fold\".format(i))\n",
    "    train_df = d.iloc[train_index]\n",
    "    test_df = d.iloc[test_index]\n",
    "            \n",
    "\n",
    "    model = train_model2(train_df, 1, 0.5, 25)\n",
    "    test_df['predict_label'], test_df['predict_value'] = zip(*test_df.apply(lambda x: predict2(model, x), axis=1))\n",
    "\n",
    "    result.append(test_df.copy())\n",
    "\n",
    "    i += 1\n",
    "\n",
    "temp_df = pd.concat(result)  \n",
    "for label in df['category'].drop_duplicates().tolist():\n",
    "    true_positives = temp_df[(temp_df.predict_label == label) & (temp_df.category == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "    try:\n",
    "        precision = true_positives/temp_df[(temp_df.predict_label == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "    except:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = true_positives/temp_df[temp_df.category == label].shape[0]\n",
    "    except:\n",
    "        recall = 0\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall/(precision + recall)\n",
    "    except:\n",
    "        f1 = 0\n",
    "    number = temp_df[temp_df.category == label].shape[0]\n",
    "    data.append([label, precision, recall, f1, number])\n",
    "stat_df = pd.DataFrame(data, columns = ['label', 'precision', 'recall', 'f1', 'count'])\n",
    "macrof1 = stat_df['f1'].mean()\n",
    "weightedf1 = stat_df['f1'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "macroprecision = stat_df['precision'].mean()\n",
    "weightedprecision = stat_df['precision'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "macrorecall = stat_df['recall'].mean()\n",
    "weightedrecall = stat_df['recall'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "\n",
    "print('Macro F1: {}'.format(macrof1))\n",
    "print('Weighted F1: {}'.format(weightedf1))\n",
    "print('Macro Precision: {}'.format(macroprecision))\n",
    "print('Weighted Precision: {}'.format(weightedprecision))\n",
    "print('Macro Recall: {}'.format(macrorecall))\n",
    "print('Weighted Recall: {}'.format(weightedrecall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final Weighted F1-score is 88.66%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There is also one factor that control our model is threshold value to control the balance between precision and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold_data = []\n",
    "for threshold in [0, 0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8, 0.85, 0.9, 0.95]:\n",
    "    data = []\n",
    "    for label in df['category'].drop_duplicates().tolist():\n",
    "        true_positives = temp_df[(temp_df.predict_label == label) & (temp_df.category == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "        try:\n",
    "            precision = true_positives/temp_df[(temp_df.predict_label == label) & (temp_df.predict_value>=threshold)].shape[0]\n",
    "        except:\n",
    "            precision = 0\n",
    "        try:\n",
    "            recall = true_positives/temp_df[temp_df.category == label].shape[0]\n",
    "        except:\n",
    "            recall = 0\n",
    "\n",
    "        try:\n",
    "            f1 = 2*precision*recall/(precision + recall)\n",
    "        except:\n",
    "            f1 = 0\n",
    "        number = temp_df[temp_df.category == label].shape[0]\n",
    "        data.append([label, precision, recall, f1, number])\n",
    "    stat_df = pd.DataFrame(data, columns = ['label', 'precision', 'recall', 'f1', 'count'])\n",
    "    weightedf1 = stat_df['f1'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "    weightedprecision = stat_df['precision'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "    weightedrecall = stat_df['recall'].values.dot(stat_df['count'].values)/stat_df['count'].sum()\n",
    "\n",
    "    threshold_data.append([threshold,weightedprecision,weightedrecall,weightedf1])\n",
    "    \n",
    "threshold_df = pd.DataFrame(threshold_data, columns = ['threshold', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax = threshold_df.plot(ax=ax, kind='line', x='threshold', y='precision', label='precision')\n",
    "ax = threshold_df.plot(ax=ax, kind='line', x='threshold', y='recall', label='recall')\n",
    "ax = threshold_df.plot(ax=ax, kind='line', x='threshold', y='f1', label='f1')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the model is quite stable upto threshold value 0.4, and then precision can go up to 95% with recall value goes down to 75%. Based on the scope and requirements of application, we should change the threshold accordingly. I would choose the value of 0.5 because that's when the slope of recall becomes much steeper, and we got a small boost in precision from 88% to 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a class=\"anchor\" id=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I did some analysis to the data and also trained a Machine Learning model to automatically categorize an articles. There are still lots of things we need to explore and optimize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a news application, the word dictionary is very general, cover all kinds of topics. Taking more data will help a lot to make our model smarter, as shown when we use a general pretrained word vectors from multiple articles around internet. Of course using our data for word vectors is still better if we want to focus on some kind of topics (more about life, technology and less about wars for example). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category that we defined also plays a big factor in our model. The current categories is still a bit confusing, and we need to consider if we should have a hierachy structure for categories, in case we want to have deeper understanding level of the article or not. Some categories are still overlapped together, and we should have a strategy to deal with those cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The url part that we have is also very useful. We can learn from it to better categorize our platform, as well as increase its priority in our classification by repeating multiple times before concatenating. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fasttext model I created is quite small and practical in production, with one small server to run the model. However it's not suitable if we want to have deeper understanding for other purpose. We may need to use other deep learning techniques and having bigger infrastructure to house it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
